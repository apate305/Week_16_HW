{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0283fc37",
   "metadata": {},
   "source": [
    "1.\tPerform combined over and under sampling on the diabetes dataset (use SMOTEENN). Explain how combined sampling works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ab3c4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report, plot_confusion_matrix\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Below are the neccessary libraries for SMOTE-ENN\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.under_sampling import EditedNearestNeighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63e7f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1041c623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df = pd.read_csv(\"diabetes copy2.csv\") \n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c595b3",
   "metadata": {},
   "source": [
    "## Evaluating Dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32a2a7d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5143674d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84281b54",
   "metadata": {},
   "source": [
    "## SMOTE-ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7caeaab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Features (X) and Target (Y)\n",
    "y=diabetes_df['Outcome'].values\n",
    "X=diabetes_df.drop('Outcome',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34f62bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.7322\n",
      "Mean Precision: 0.7271\n",
      "Mean Recall: 0.7459\n"
     ]
    }
   ],
   "source": [
    "##Using SMOTE-ENN to balance the data\n",
    "\n",
    "#Define model: \n",
    "    #This model does the following:\n",
    "    #1. Random sample of data is used for training the model\n",
    "    #2. Then, the next version of the model compensate for the weaknesses of the previous model. \n",
    "    #3. So with each iteration, the model gets better and eventually becomes a strong predictor. \n",
    "#AdaBoost can be used to boost the performance of any machine learning algorithm. In this case it is\n",
    "#boosting the performance of the SMOTEENN. \n",
    "model=AdaBoostClassifier()\n",
    "\n",
    "#Define SMOTE-ENN:\n",
    "\n",
    "#the sampling_strategy used is 'all' since the ENN purpose is to delete observations from both of the classes \n",
    "# where the observation's class is different than its KNN majority class. ASK ABOUT THIS!!\n",
    "resample=SMOTEENN(enn=EditedNearestNeighbours(sampling_strategy='all'))\n",
    "\n",
    "#Define pipeline:\n",
    "    #Pipeline is a sequence of data processing steps. Here I have identified the functions (resample and model)\n",
    "    #I want in the data processing steps\n",
    "pipeline=Pipeline(steps=[('r', resample), ('m', model)])\n",
    "\n",
    "#Define evaluation procedure (here we use Repeated Stratified K-Fold CV) 10 even groups\n",
    "#Why we do a cross validation:\n",
    "    # when calculating the accuracy score (R2), this score is dependent on the way that you split the data.\n",
    "    # Sometimes the test set can contain some things that skew the accuracy score so this is why it is\n",
    "    # important to have different train sets (10 even groups).\n",
    "cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "#Evaluate model\n",
    "scoring=['accuracy','precision_macro','recall_macro']\n",
    "scores = cross_validate(pipeline, X, y, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "\n",
    "# summarize performance\n",
    "print('Mean Accuracy: %.4f' % np.mean(scores['test_accuracy']))\n",
    "print('Mean Precision: %.4f' % np.mean(scores['test_precision_macro']))\n",
    "print('Mean Recall: %.4f' % np.mean(scores['test_recall_macro']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "debb9bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1: 289, 0: 229})\n"
     ]
    }
   ],
   "source": [
    "#fit the new data \n",
    "X_res, y_res = resample.fit_resample(X, y)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "771f49d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.100000</td>\n",
       "      <td>0.167000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.600000</td>\n",
       "      <td>0.191000</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.400000</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>66</td>\n",
       "      <td>15</td>\n",
       "      <td>140</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>0.487000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>117</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.100000</td>\n",
       "      <td>0.337000</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>3</td>\n",
       "      <td>147</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.254453</td>\n",
       "      <td>0.575211</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>9</td>\n",
       "      <td>155</td>\n",
       "      <td>92</td>\n",
       "      <td>47</td>\n",
       "      <td>234</td>\n",
       "      <td>37.600000</td>\n",
       "      <td>0.671521</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>5</td>\n",
       "      <td>143</td>\n",
       "      <td>82</td>\n",
       "      <td>26</td>\n",
       "      <td>286</td>\n",
       "      <td>32.262898</td>\n",
       "      <td>0.454775</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>7</td>\n",
       "      <td>129</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.228964</td>\n",
       "      <td>0.580238</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>93</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>49.385632</td>\n",
       "      <td>0.355431</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>518 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin        BMI  \\\n",
       "0              1       89             66             23       94  28.100000   \n",
       "1              4      110             92              0        0  37.600000   \n",
       "2              8       99             84              0        0  35.400000   \n",
       "3              1       97             66             15      140  23.200000   \n",
       "4              5      117             92              0        0  34.100000   \n",
       "..           ...      ...            ...            ...      ...        ...   \n",
       "513            3      147             91              0        0  31.254453   \n",
       "514            9      155             92             47      234  37.600000   \n",
       "515            5      143             82             26      286  32.262898   \n",
       "516            7      129             67              0        0  33.228964   \n",
       "517            1      147             93             41        0  49.385632   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  \n",
       "0                    0.167000   21  \n",
       "1                    0.191000   30  \n",
       "2                    0.388000   50  \n",
       "3                    0.487000   22  \n",
       "4                    0.337000   38  \n",
       "..                        ...  ...  \n",
       "513                  0.575211   61  \n",
       "514                  0.671521   47  \n",
       "515                  0.454775   58  \n",
       "516                  0.580238   45  \n",
       "517                  0.355431   28  \n",
       "\n",
       "[518 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c65728c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3515147",
   "metadata": {},
   "source": [
    "## How Combined Sampling Works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f10488",
   "metadata": {},
   "source": [
    "### The following is one way combined sampling can work:\n",
    "\n",
    "Scenario: Dataset with a 1:100 class distribution-\n",
    "\n",
    "- 1) Apply oversampling (duplicate examples from minority group) to increase the ratio to 1:10\n",
    "\n",
    "            Sampling_strategy = 0.1 (10%) \n",
    "            \n",
    "- 2) Then, apply undersampling (delete from majority group) to improve the ratio to 1:2\n",
    "\n",
    "            Sampling_strategy = 0.5 (50%)\n",
    "\n",
    "        \n",
    "Combined sampling is done to increase model performance even more than just doing over or under sampling.         \n",
    "\n",
    "We can do combinded sampling by applying SMOTE and ENN (SMOTE-ENN) because SMOTE is a oversampling techinique and ENN is a undersampling techinique. \n",
    "\n",
    "- SMOTE is an oversampling method where minority class samples are generated. In some oversampling techniques, the data from the minority class is simply duplicated. This does not produce any new information. SMOTE helps solve this issue because it generates synthetic minority data. \n",
    "    \n",
    "\n",
    "- The ENN method works by: \n",
    "\n",
    "    1) Finding the KNN of each unknown observation/new data pt/test pt \n",
    "\n",
    "    2) Check whether the majority class from the observation’s KNN is the same as the observation’s class or not. \n",
    "\n",
    "    3) If the majority class of the observation’s KNN is different from the observation’s class then both the observaton and the KNN are removed. \n",
    "\n",
    "    4) The steps above are repeated until the right proprotion is reached. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5701ef4",
   "metadata": {},
   "source": [
    "2.\tPerform logistic regression with the new data from question 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d038a98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9326923076923077"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size = 0.2, random_state=42, stratify=y_res)\n",
    "\n",
    "#Standardize\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)\n",
    "\n",
    "#Logistic regression approach\n",
    "regression = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "y_predicted = regression.predict(X_test)\n",
    "\n",
    "\n",
    "regression.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2e4478d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92        46\n",
      "           1       0.95      0.93      0.94        58\n",
      "\n",
      "    accuracy                           0.93       104\n",
      "   macro avg       0.93      0.93      0.93       104\n",
      "weighted avg       0.93      0.93      0.93       104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report\n",
    "\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee760f6",
   "metadata": {},
   "source": [
    "a.\tComment on the performance of combined sampling vs the other approaches we have used for the diabetes dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5c27b4",
   "metadata": {},
   "source": [
    "The above classification report is saying for all of the '0s' (Not diabetic or true negatives), there was a 91% precision in our prediction (I was 91% correct in predicting true negatives.) For all the '1s' (Diabetic or true positives) there was a 95% precison. (I was 95% correct in predicting true positives.)\n",
    "\n",
    "The recall values are also high with both recalls being 93%. So out of all the data that was true negative or true positive, the model was able to ctahc 93% of it. \n",
    "\n",
    "In week 14's hw I used only highly correlated features to see if that affected the performance of the logistic regression model. This didn't make a whole lot of difference since accuracy was still at 70% in spite of using specific features. Compared to that, the logistic regression performance here after doing combined sampleing is much better.\n",
    "\n",
    "- Just doing oversampling--SMOTE\n",
    "\n",
    "- decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c804c7",
   "metadata": {},
   "source": [
    "3.\tCreate an ROC Curve for the model \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html and calculate the AUC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "65e4db40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To plot the ROC curve, the following needs to be imported\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Compute predicted probabilities (evaluate logistic regression model's performance by plotting an ROC curve)\n",
    "    #Classifiers in scikit-learn (like LR) have a .predict_proba() method which returns the probability of a \n",
    "    #given sample being in a particular class.   \n",
    "# regression refers to logistic regression\n",
    "y_pred_prob = regression.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Generate ROC curve values: false positive rate, true positive rate, thresholds\n",
    "    #Pass in y_test and y_pred_prob (test labels and predicted outcomes/probabilities) \n",
    "    #to the roc_curve() function and separate the result into the 3 variables \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve: plot the FPR and TPR:\n",
    "# It is a plot of the false positive rate (x-axis, false alarm rate/incorrectly diabetic) versus the \n",
    "#true positive rate (y-axis, hit rate/truely diabetic) for a number of different threshold values (0 to 1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bdf8ba4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.988\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print('AUC: %.3f' % auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7675e2",
   "metadata": {},
   "source": [
    "a.\tBRIEFLY explain what the ROC Curve shows and what the resulting AUC means. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a1f542",
   "metadata": {},
   "source": [
    "### ROC Curve\n",
    "\n",
    "The ROC curve or receiver operating characteristic curve is the set of points we get when tryng all the possible thresholds. It is a useful tool when doing predictions with two outcomes.  \n",
    "\n",
    "\n",
    "According to the ROC curve, the two classes overlap since the \"curve\" does not have a 90 degree angle at (0,1). This means that the logistic regresson model does not have 100% distinguishing abilities (distingusihing between the postive (diabetic) and negative (non-diabetic) classes.) \n",
    "\n",
    "EX: 20% FPR means a 99% TPR\n",
    "\n",
    "### AUC (Area Under The Curve): \n",
    "\n",
    "ROC is a probability curve and AUC tells how much the model is capable of distinguishing between classes. So a high AUC score would be what we're looking for. In this case the AUC score is 98%. This means that there is 98% chance that the logistic regression model will be able to differentiate between diabetic and non-diabetic. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80680d9f",
   "metadata": {},
   "source": [
    "4.\tWhat is outlier detection? Why is it useful? What methods can you use for outlier detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c9aa4c",
   "metadata": {},
   "source": [
    "Outlier detction is the process of detecting outliers in a dataset that can skew the data and influence our overall understanding of the data set. Outliers are those points that deviate from the rest of the observations in the data. \n",
    "\n",
    "Some types of outlier detections are Z-score, Dbscan and Isolation forests.\n",
    "\n",
    "- Z-score: this score indicates how many standard deviations a data point is from the average.\n",
    "- Dbscan (Density Based Spatial Clustering of Applications with Noise): This is a clustering algorith that groups together points that are close in proximity and as a result it also points out the outliers since they are in low-density regions. \n",
    "\n",
    "- Isolation Forests: this method works by selecting a column and its values at random in order to separate different parts of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5b7ae6",
   "metadata": {},
   "source": [
    "5.\tPerform a linear SVM to predict credit approval (last column) using this dataset: \n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Statlog+%28Australian+Credit+Approval%29 . \n",
    "\n",
    "Make sure you look at the accompanying document that describes the data in the dat file. You will need to either convert this data to another file type or import the dat file to python. \n",
    "\n",
    "You can use this code, but otherwise you follow standard practices we have already used many times: \n",
    "\n",
    "\n",
    "- from sklearn.svm import SVC\n",
    "- classifier = SVC(kernel='linear')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "00c91530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000e+00, 2.208e+01, 1.146e+01, ..., 1.000e+02, 1.213e+03,\n",
       "        0.000e+00],\n",
       "       [0.000e+00, 2.267e+01, 7.000e+00, ..., 1.600e+02, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       [0.000e+00, 2.958e+01, 1.750e+00, ..., 2.800e+02, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       ...,\n",
       "       [0.000e+00, 1.883e+01, 9.540e+00, ..., 1.000e+02, 1.000e+00,\n",
       "        1.000e+00],\n",
       "       [0.000e+00, 2.742e+01, 1.450e+01, ..., 1.200e+02, 1.200e+01,\n",
       "        1.000e+00],\n",
       "       [1.000e+00, 4.100e+01, 4.000e-02, ..., 5.600e+02, 1.000e+00,\n",
       "        1.000e+00]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the .dat file as an array\n",
    "australia_array = sed = np.loadtxt('australian.dat')\n",
    "australia_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fda65b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>22.08</td>\n",
       "      <td>11.460</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>22.67</td>\n",
       "      <td>7.000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>29.58</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>21.67</td>\n",
       "      <td>11.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.17</td>\n",
       "      <td>8.170</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.960</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>1.0</td>\n",
       "      <td>31.57</td>\n",
       "      <td>10.500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.67</td>\n",
       "      <td>0.415</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18.83</td>\n",
       "      <td>9.540</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0.0</td>\n",
       "      <td>27.42</td>\n",
       "      <td>14.500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>1.0</td>\n",
       "      <td>41.00</td>\n",
       "      <td>0.040</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1       2    3     4    5      6    7    8     9    10   11  \\\n",
       "0    1.0  22.08  11.460  2.0   4.0  4.0  1.585  0.0  0.0   0.0  1.0  2.0   \n",
       "1    0.0  22.67   7.000  2.0   8.0  4.0  0.165  0.0  0.0   0.0  0.0  2.0   \n",
       "2    0.0  29.58   1.750  1.0   4.0  4.0  1.250  0.0  0.0   0.0  1.0  2.0   \n",
       "3    0.0  21.67  11.500  1.0   5.0  3.0  0.000  1.0  1.0  11.0  1.0  2.0   \n",
       "4    1.0  20.17   8.170  2.0   6.0  4.0  1.960  1.0  1.0  14.0  0.0  2.0   \n",
       "..   ...    ...     ...  ...   ...  ...    ...  ...  ...   ...  ...  ...   \n",
       "685  1.0  31.57  10.500  2.0  14.0  4.0  6.500  1.0  0.0   0.0  0.0  2.0   \n",
       "686  1.0  20.67   0.415  2.0   8.0  4.0  0.125  0.0  0.0   0.0  0.0  2.0   \n",
       "687  0.0  18.83   9.540  2.0   6.0  4.0  0.085  1.0  0.0   0.0  0.0  2.0   \n",
       "688  0.0  27.42  14.500  2.0  14.0  8.0  3.085  1.0  1.0   1.0  0.0  2.0   \n",
       "689  1.0  41.00   0.040  2.0  10.0  4.0  0.040  0.0  1.0   1.0  0.0  1.0   \n",
       "\n",
       "        12      13   14  \n",
       "0    100.0  1213.0  0.0  \n",
       "1    160.0     1.0  0.0  \n",
       "2    280.0     1.0  0.0  \n",
       "3      0.0     1.0  1.0  \n",
       "4     60.0   159.0  1.0  \n",
       "..     ...     ...  ...  \n",
       "685    0.0     1.0  1.0  \n",
       "686    0.0    45.0  0.0  \n",
       "687  100.0     1.0  1.0  \n",
       "688  120.0    12.0  1.0  \n",
       "689  560.0     1.0  1.0  \n",
       "\n",
       "[690 rows x 15 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert the array to a dataframe\n",
    "australia_df = pd.DataFrame(australia_array)\n",
    "australia_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bde2f090",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new column names assigned\n",
    "australia_df.columns = [\"A1\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\", \"A8\", \"A9\", \"A10\", \"A11\", \"A12\", \"A13\", \"A14\", \"A15\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "714d01e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>22.08</td>\n",
       "      <td>11.460</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>22.67</td>\n",
       "      <td>7.000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>29.58</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>21.67</td>\n",
       "      <td>11.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.17</td>\n",
       "      <td>8.170</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.960</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>1.0</td>\n",
       "      <td>31.57</td>\n",
       "      <td>10.500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.67</td>\n",
       "      <td>0.415</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18.83</td>\n",
       "      <td>9.540</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0.0</td>\n",
       "      <td>27.42</td>\n",
       "      <td>14.500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>1.0</td>\n",
       "      <td>41.00</td>\n",
       "      <td>0.040</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A1     A2      A3   A4    A5   A6     A7   A8   A9   A10  A11  A12  \\\n",
       "0    1.0  22.08  11.460  2.0   4.0  4.0  1.585  0.0  0.0   0.0  1.0  2.0   \n",
       "1    0.0  22.67   7.000  2.0   8.0  4.0  0.165  0.0  0.0   0.0  0.0  2.0   \n",
       "2    0.0  29.58   1.750  1.0   4.0  4.0  1.250  0.0  0.0   0.0  1.0  2.0   \n",
       "3    0.0  21.67  11.500  1.0   5.0  3.0  0.000  1.0  1.0  11.0  1.0  2.0   \n",
       "4    1.0  20.17   8.170  2.0   6.0  4.0  1.960  1.0  1.0  14.0  0.0  2.0   \n",
       "..   ...    ...     ...  ...   ...  ...    ...  ...  ...   ...  ...  ...   \n",
       "685  1.0  31.57  10.500  2.0  14.0  4.0  6.500  1.0  0.0   0.0  0.0  2.0   \n",
       "686  1.0  20.67   0.415  2.0   8.0  4.0  0.125  0.0  0.0   0.0  0.0  2.0   \n",
       "687  0.0  18.83   9.540  2.0   6.0  4.0  0.085  1.0  0.0   0.0  0.0  2.0   \n",
       "688  0.0  27.42  14.500  2.0  14.0  8.0  3.085  1.0  1.0   1.0  0.0  2.0   \n",
       "689  1.0  41.00   0.040  2.0  10.0  4.0  0.040  0.0  1.0   1.0  0.0  1.0   \n",
       "\n",
       "       A13     A14  A15  \n",
       "0    100.0  1213.0  0.0  \n",
       "1    160.0     1.0  0.0  \n",
       "2    280.0     1.0  0.0  \n",
       "3      0.0     1.0  1.0  \n",
       "4     60.0   159.0  1.0  \n",
       "..     ...     ...  ...  \n",
       "685    0.0     1.0  1.0  \n",
       "686    0.0    45.0  0.0  \n",
       "687  100.0     1.0  1.0  \n",
       "688  120.0    12.0  1.0  \n",
       "689  560.0     1.0  1.0  \n",
       "\n",
       "[690 rows x 15 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check new names\n",
    "australia_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5b15f2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Features (X) and Target (Y)\n",
    "data = australia_df.drop('A15',axis=1) #X\n",
    "target = australia_df['A15'] #y\n",
    "\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size = 0.2, random_state=42, stratify=target)\n",
    "\n",
    "#Standardize\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cc469b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8786231884057971"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "classifier = SVC(kernel='linear')\n",
    "\n",
    "svm = LinearSVC()\n",
    "\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "svm.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1e811c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55 22]\n",
      " [ 4 57]]\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = svm.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred2)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4560b0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.71      0.81        77\n",
      "         1.0       0.72      0.93      0.81        61\n",
      "\n",
      "    accuracy                           0.81       138\n",
      "   macro avg       0.83      0.82      0.81       138\n",
      "weighted avg       0.84      0.81      0.81       138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CR = classification_report(y_test, y_pred2)\n",
    "print(CR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fce0e18",
   "metadata": {},
   "source": [
    "a.\tHow did the SVM model perform? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17121ced",
   "metadata": {},
   "source": [
    "## Background on LinearSVC\n",
    "\n",
    "- Basic Support Vector Machine (SVM) classifier is called Linear support vector classifier (LinearSVC). \n",
    "\n",
    "- SVMs are supervised machine learning algorithms. \n",
    "\n",
    "### What is SVM  (and LinearSVC) ?\n",
    "\n",
    "- SVM is an algorithm that finds a hyperplane or line that separates the labeled dataset into two classes.\n",
    "\n",
    "- The support vectors are those data points are closest to the hyperplane and they are crutial in detremining the placement of the hyperplane because removing the points would alter the posiiton of the \"decision line\".\n",
    "\n",
    "- How is a hyperplane formed? Through determining the exact margin. \n",
    "\n",
    "        Margin is the distance between the hyperplane and the closest point from either set.\n",
    "        \n",
    "        EXACT MARGIN:\n",
    "        \n",
    "        - Maximum possible margin between the hyperplane and any point in the data. So that the hyperplane  \n",
    "        gives a fair chance to classify new data correctly.\n",
    "\n",
    "### Predicting Test Data (after performing LinearSVC)\n",
    "\n",
    "- When new data (test set) is added, whatever side of the hyperplane it goes will determine the class of the test. \n",
    "\n",
    "## SVM MODEL PERFORMANCE:\n",
    "\n",
    "The SVM model seems to have performed pretty well given the precision and recall scores are high for both true negatives and true positives. Additionally the accuracy (r squared) score is also high. \n",
    "\n",
    "A precision score of 93% for true negatives indicates that out of the values that were predicted as negatives by the model, 93% were true negatives. \n",
    "\n",
    "\n",
    "A Recall score of 71% for true negatives indicates that out of total amount of true negatives, the model caught 71% of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b8b466",
   "metadata": {},
   "source": [
    "6.\tWhat kinds of jobs in data are you most interested in? Do some research on what is out there. Write about your thoughts in under 400 words. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bb9c30",
   "metadata": {},
   "source": [
    "### Business Analyst\n",
    "\n",
    "Business analysts look at  past and present business data and evaluate it with the goal of improving decision-making. They are between IT and business.  \n",
    "\n",
    "### Business Analyst Job Roles:\n",
    "\n",
    "- Create a analysis includeing pointing out problems, and their solutions\n",
    "- Budgeting and predicting\n",
    "- Variance analysis\n",
    "- Defining business requirements and reporting them back to stakeholders\n",
    "\n",
    "NOT TO SELF: \n",
    "\n",
    "- Not all business analysts need a IT background, they just need a basic idea of how programming works.\n",
    "      \n",
    "- SQL knowledge is a prerequisite for almost any business analyst job\n",
    "- Python skills is required sometimes\n",
    "\n",
    "### Data Analysis\n",
    "\n",
    "- Create and continue to update data systems and databases; \n",
    "    - Fixing coding errors\n",
    "- Discover patterns in data--look at primary and secondary sources (WHAT DOES THIS ENTAIL?) \n",
    "- Reorganize data in a readable format. \n",
    "- Interprete data sets with statistical tools\n",
    "    -Like predictiing future points \n",
    "- Prep data reports for audience (teammates)    \n",
    "    - Communicate trends, patterns, and predictions     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f33ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
